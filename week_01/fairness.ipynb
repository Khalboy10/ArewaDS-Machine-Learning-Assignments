{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Fairness in machine learning refers to the idea that machine learning algorithms should not systematically discriminate against certain groups of people based on their gender, race, ethnicity, age, religion, or other characteristics. it is the prevention of manipulating data to support bias conclusion. Fairness is the goal to ensure that machine learning models are unbiased.\n",
    "\n",
    "Achieving fairness in machine learning can be challenging because machine learning algorithms are often trained on historical data that reflects biases. To address this issue, researchers and practitioners have developed a range of techniques for measuring and mitigating bias in machine learning, such as:\n",
    "\n",
    "* Fairness metrics: These are quantitative measures used to assess how fair or unbiased a machine learning model is. Common metrics include disparate impact, equal opportunity, and predictive parity.\n",
    "\n",
    "* Fairness constraints: These are rules or constraints that are built into machine learning algorithms to ensure that they do not discriminate against certain groups. For example, a fairness constraint might require that a model's predictions be equally accurate for all demographic groups.\n",
    "\n",
    "* Algorithmic modifications: These are changes made to the machine learning algorithm itself to reduce bias or increase fairness. For example, an algorithm might be modified to explicitly consider sensitive attributes (such as race or gender) when making predictions.\n",
    "\n",
    "* Data preprocessing: This involves manipulating the training data to reduce bias or increase fairness. For example, data augmentation techniques can be used to create more balanced datasets that reflect the diversity of the population being modeled.\n",
    "\n",
    "Unfairness in machine learning refers to situations where machine learning models produce biased  outcomes, often against certain groups of people based on their gender, race, ethnicity, age, religion, or other characteristics. This can occur for several reasons, such as:\n",
    "\n",
    "* Biased training data: If the machine learning algorithm is trained on data that is biased, it may learn to replicate and perpetuate those biases.\n",
    "\n",
    "* Incorrect assumptions: If the machine learning algorithm is built on incorrect assumptions or flawed logic, it may produce biased or discriminatory results.\n",
    "\n",
    "* Limited transparency: If the machine learning algorithm is not transparent, it can be difficult to identify and correct instances of bias or discrimination.\n",
    "\n",
    "* Lack of diversity: If the developers of the machine learning algorithm and the data used to train it do not reflect the diversity of the population,  the algorithm may not account for the experiences and perspectives of underrepresented groups.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0rc1 (main, Aug 12 2022, 10:02:14) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ead1b95f633dc9c51826328e1846203f51a198c6fb5f2884a80417ba131d4e82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
